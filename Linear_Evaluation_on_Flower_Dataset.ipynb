{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Evaluation on Flower Dataset",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPD4yJ8jgXy9dqR7w6SBcyw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayulockin/SwAV-TF/blob/master/Linear_Evaluation_on_Flower_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8fMXBGWztKi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "fcbba2e9-55e4-4ce9-cb32-7082d3b6180b"
      },
      "source": [
        "!git clone https://username:password@github.com/ayulockin/SwAV-TF.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SwAV-TF'...\n",
            "remote: Enumerating objects: 110, done.\u001b[K\n",
            "remote: Counting objects: 100% (110/110), done.\u001b[K\n",
            "remote: Compressing objects: 100% (102/102), done.\u001b[K\n",
            "remote: Total 110 (delta 48), reused 22 (delta 8), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (110/110), 10.81 MiB | 795.00 KiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O-8mYyD0CiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('SwAV-TF/utils')\n",
        "\n",
        "import architecture"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1c99jQL0KMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "\n",
        "from tqdm import tqdm\n",
        "from imutils import paths\n",
        "\n",
        "tf.random.set_seed(666)\n",
        "np.random.seed(666)\n",
        "\n",
        "tfds.disable_progress_bar()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eaekTr10Yzn",
        "colab_type": "text"
      },
      "source": [
        "## Restoring model weights from GCS Bucket"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LROY2Mrn0wpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import get_file"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiEZfPfG0TeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_backbone_urlpath = \"https://storage.googleapis.com/swav-tf/feature_backbone_20_epochs.h5\"\n",
        "prototype_urlpath = \"https://storage.googleapis.com/swav-tf/projection_prototype_20_epochs.h5\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pEVJ4Y70isN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "2e5cd112-10a7-4287-b092-0858bd94d4d0"
      },
      "source": [
        "feature_backbone_weights = get_file('swav_feature_weights', feature_backbone_urlpath)\n",
        "prototype_weights = get_file('swav_prototype_projection_weights', prototype_urlpath)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/swav-tf/feature_backbone_20_epochs.h5\n",
            "94584832/94583160 [==============================] - 3s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/swav-tf/projection_prototype_20_epochs.h5\n",
            "17907712/17900192 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnhWEo8_12FK",
        "colab_type": "text"
      },
      "source": [
        "## Dataset gathering and preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAOhOFMs110h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "25a3bc26-4194-4f18-800e-d91576fb73a3"
      },
      "source": [
        "# Gather Flowers dataset\n",
        "train_ds, _, validation_ds = tfds.load(\n",
        "    \"tf_flowers\",\n",
        "    split=[\"train[:10%]\", \"train[10%:85%]\", \"train[85%:]\"], # notice 10% of the images was used for training our linear evaluater. \n",
        "    data_dir='tf_dataset',\n",
        "    as_supervised=True\n",
        ")\n",
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "@tf.function\n",
        "def scale_resize_image(image, label):\n",
        "    image = tf.image.resize(image, (224, 224)) # Resizing to high resolution used while training swav\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    return (image, label)\n",
        "\n",
        "train_ds = (\n",
        "    train_ds\n",
        "    .map(scale_resize_image, num_parallel_calls=AUTO)\n",
        "    .batch(32)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "test_ds = (\n",
        "    validation_ds\n",
        "    .map(scale_resize_image, num_parallel_calls=AUTO)\n",
        "    .batch(32)\n",
        "    .prefetch(AUTO)\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset tf_flowers/3.0.0 (download: 218.21 MiB, generated: Unknown size, total: 218.21 MiB) to tf_dataset/tf_flowers/3.0.0...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset tf_flowers is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead set\n",
            "data_dir=gs://tfds-data/datasets.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDataset tf_flowers downloaded and prepared to tf_dataset/tf_flowers/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqOBLHJa5Ztp",
        "colab_type": "text"
      },
      "source": [
        "## Get SwAV architecture and Build Linear Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znqofzfr46-4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "0b1174e2-3777-4c2e-f5b8-362bca090457"
      },
      "source": [
        "feature_backbone = architecture.get_resnet_backbone()\n",
        "feature_backbone.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, None, None, 3)]   0         \n",
            "_________________________________________________________________\n",
            "resnet50 (Functional)        (None, None, None, 2048)  23587712  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "=================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc3OJGyP5kj1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "c182dac9-7bf7-490d-854b-0a7db2742ffd"
      },
      "source": [
        "projection_prototype = architecture.get_projection_prototype(15)\n",
        "projection_prototype.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 2048)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 2048)         4196352     input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 2048)         8192        dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 2048)         0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          262272      activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Square (TensorFlowO [(None, 128)]        0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum (TensorFlowOpLa [(None, 1)]          0           tf_op_layer_Square[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Maximum (TensorFlow [(None, 1)]          0           tf_op_layer_Sum[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Rsqrt (TensorFlowOp [(None, 1)]          0           tf_op_layer_Maximum[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mul (TensorFlowOpLa [(None, 128)]        0           dense_1[0][0]                    \n",
            "                                                                 tf_op_layer_Rsqrt[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "prototype (Dense)               (None, 15)           1920        tf_op_layer_Mul[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 4,468,736\n",
            "Trainable params: 4,464,640\n",
            "Non-trainable params: 4,096\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkRBnNMuM0Za",
        "colab_type": "text"
      },
      "source": [
        "#### Load trained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzLNXTSh5yCX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_backbone.load_weights(feature_backbone_weights)\n",
        "projection_prototype.load_weights(prototype_weights)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kDPnyoNM3Rp",
        "colab_type": "text"
      },
      "source": [
        "#### Linear Evaluater"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC71hdXX6ALS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_linear_model(features):\n",
        "    linear_model = Sequential([Dense(5, input_shape=(features, ), activation=\"softmax\")])\n",
        "    return linear_model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTzkBKMx6tBG",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gy_tO6wFV7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_image_representation(trainloader):\n",
        "    # get embedding from feature backbone model\n",
        "    embeddings = []\n",
        "    labels = []\n",
        "    for image, label in trainloader:\n",
        "        labels.extend(label)\n",
        "\n",
        "        embedding = feature_backbone.predict(image)\n",
        "        embeddings.extend(embedding.tolist())\n",
        "    embeddings = np.array(embeddings)\n",
        "\n",
        "    # get projection from trained projection head\n",
        "    projections, prototypes = projection_prototype(embeddings)\n",
        "\n",
        "    return np.array(embeddings), np.array(projections), np.array(prototypes), np.array(labels)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ncBWS9TGEXt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "348b0811-2c43-4491-c79e-d23f6c872faa"
      },
      "source": [
        "train_embeddings, train_projections, _, train_labels = get_image_representation(train_ds)\n",
        "test_embeddings, test_projections, _, test_labels = get_image_representation(test_ds)\n",
        "\n",
        "print(train_embeddings.shape, train_projections.shape, train_labels.shape)\n",
        "print(test_embeddings.shape, test_projections.shape, test_labels.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(367, 2048) (367, 128) (367,)\n",
            "(550, 2048) (550, 128) (550,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vECu62eyCdut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Early Stopping to prevent overfitting\n",
        "early_stopper = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, verbose=2, restore_best_weights=True)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RArUvFToDJKn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "outputId": "d3aa95ef-9d61-4aa9-c8e2-055b4f01e0c5"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "linear_model = get_linear_model(128)\n",
        "linear_model.summary()\n",
        "\n",
        "linear_model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
        "                     optimizer=\"adam\")\n",
        "\n",
        "history = linear_model.fit(train_projections, train_labels,\n",
        "                 validation_data=(test_projections, test_labels),\n",
        "                 batch_size=32,\n",
        "                 epochs=35,\n",
        "                 callbacks=[early_stopper])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 645\n",
            "Trainable params: 645\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/35\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.6138 - acc: 0.1717 - val_loss: 1.6159 - val_acc: 0.1855\n",
            "Epoch 2/35\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.6008 - acc: 0.2398 - val_loss: 1.6143 - val_acc: 0.2036\n",
            "Epoch 3/35\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5943 - acc: 0.2888 - val_loss: 1.6145 - val_acc: 0.2036\n",
            "Epoch 4/35\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.5891 - acc: 0.2888 - val_loss: 1.6175 - val_acc: 0.2036\n",
            "Epoch 5/35\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.5870 - acc: 0.2888 - val_loss: 1.6192 - val_acc: 0.2036\n",
            "Epoch 6/35\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5861 - acc: 0.2888 - val_loss: 1.6194 - val_acc: 0.2036\n",
            "Epoch 7/35\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 1.5929 - acc: 0.2812Restoring model weights from the end of the best epoch.\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.5859 - acc: 0.2888 - val_loss: 1.6231 - val_acc: 0.2036\n",
            "Epoch 00007: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}