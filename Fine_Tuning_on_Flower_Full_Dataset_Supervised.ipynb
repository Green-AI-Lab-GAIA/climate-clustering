{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine_Tuning_on_Flower_Full_Dataset_Supervised.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayulockin/SwAV-TF/blob/master/Fine_Tuning_on_Flower_Full_Dataset_Supervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIjCKN58nCj0",
        "colab_type": "text"
      },
      "source": [
        "# Imports and Setups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1c99jQL0KMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "\n",
        "tf.random.set_seed(666)\n",
        "np.random.seed(666)\n",
        "\n",
        "tfds.disable_progress_bar()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_u5flNSnKMq",
        "colab_type": "text"
      },
      "source": [
        "### W&B - Experiment Tracking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83g5TEyenP-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install wandb"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj0h9qQCnUBv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "a83f1788-ee67-46c6-bb97-f1935b2280b7"
      },
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "wandb.login()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://app.wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Not authenticated.  Copy a key from https://app.wandb.ai/authorize\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "API Key: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnhWEo8_12FK",
        "colab_type": "text"
      },
      "source": [
        "### Dataset gathering and preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAOhOFMs110h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "83f9d110-476d-4854-de5f-5cf9499cef40"
      },
      "source": [
        "# Gather Flowers dataset\n",
        "train_ds, validation_ds = tfds.load(\n",
        "    \"tf_flowers\",\n",
        "    split=[\"train[:85%]\", \"train[85%:]\"],\n",
        "    as_supervised=True\n",
        ")\n",
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "@tf.function\n",
        "def scale_resize_image(image, label):\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = tf.image.resize(image, (224, 224)) # Resizing to highest resolution used while training swav\n",
        "    return (image, label)\n",
        "\n",
        "training_ds = (\n",
        "    train_ds\n",
        "    .map(scale_resize_image, num_parallel_calls=AUTO)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "testing_ds = (\n",
        "    validation_ds\n",
        "    .map(scale_resize_image, num_parallel_calls=AUTO)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset tf_flowers/3.0.0 (download: 218.21 MiB, generated: Unknown size, total: 218.21 MiB) to /root/tensorflow_datasets/tf_flowers/3.0.0...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset tf_flowers is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead set\n",
            "data_dir=gs://tfds-data/datasets.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDataset tf_flowers downloaded and prepared to /root/tensorflow_datasets/tf_flowers/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqOBLHJa5Ztp",
        "colab_type": "text"
      },
      "source": [
        "### ResNet50 base and a custom classification head"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znqofzfr46-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_training_model(trainable=False):\n",
        "    inputs = layers.Input(shape=(224, 224, 3))\n",
        "    EXTRACTOR = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False,\n",
        "        input_shape=(224, 224, 3))\n",
        "    EXTRACTOR.trainable = trainable\n",
        "    x = EXTRACTOR(inputs, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(5, activation=\"softmax\")(x)\n",
        "    classifier = models.Model(inputs=inputs, outputs=x)\n",
        "    \n",
        "    return classifier"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtt4jmzzxe8Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "81994e6c-575a-4f30-ae02-cc9828720a63"
      },
      "source": [
        "model = get_training_model()\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 2s 0us/step\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 10245     \n",
            "=================================================================\n",
            "Total params: 23,597,957\n",
            "Trainable params: 10,245\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0o5LHV0pCPu",
        "colab_type": "text"
      },
      "source": [
        "### Callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vECu62eyCdut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Early Stopping to prevent overfitting\n",
        "early_stopper = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2, verbose=2, restore_best_weights=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp1fJIEYpFIC",
        "colab_type": "text"
      },
      "source": [
        "# Without Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEY1h0L2XjBJ",
        "colab_type": "text"
      },
      "source": [
        "### Warm Up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RArUvFToDJKn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52055dd4-ac5e-491b-d830-56a246d4736b"
      },
      "source": [
        "# get model and compile\n",
        "model = get_training_model()\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
        "                     optimizer='adam')\n",
        "\n",
        "# initialize wandb run\n",
        "wandb.init(entity='authors', project='swav-tf')\n",
        "\n",
        "# train\n",
        "history = model.fit(training_ds,\n",
        "                 validation_data=testing_ds,\n",
        "                 epochs=35,\n",
        "                 callbacks=[WandbCallback(),\n",
        "                            early_stopper])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/i4y0qcjk\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/i4y0qcjk</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "49/49 [==============================] - 12s 248ms/step - loss: 1.5814 - acc: 0.2885 - val_loss: 1.5539 - val_acc: 0.3109\n",
            "Epoch 2/35\n",
            "49/49 [==============================] - 11s 219ms/step - loss: 1.5063 - acc: 0.3599 - val_loss: 1.5196 - val_acc: 0.3364\n",
            "Epoch 3/35\n",
            "49/49 [==============================] - 11s 216ms/step - loss: 1.4792 - acc: 0.3849 - val_loss: 1.5015 - val_acc: 0.3527\n",
            "Epoch 4/35\n",
            "49/49 [==============================] - 11s 215ms/step - loss: 1.4616 - acc: 0.3962 - val_loss: 1.4877 - val_acc: 0.3655\n",
            "Epoch 5/35\n",
            "49/49 [==============================] - 11s 216ms/step - loss: 1.4480 - acc: 0.4058 - val_loss: 1.4758 - val_acc: 0.3764\n",
            "Epoch 6/35\n",
            "49/49 [==============================] - 11s 216ms/step - loss: 1.4365 - acc: 0.4141 - val_loss: 1.4651 - val_acc: 0.3782\n",
            "Epoch 7/35\n",
            "49/49 [==============================] - 11s 217ms/step - loss: 1.4263 - acc: 0.4215 - val_loss: 1.4552 - val_acc: 0.3891\n",
            "Epoch 8/35\n",
            "49/49 [==============================] - 11s 219ms/step - loss: 1.4171 - acc: 0.4266 - val_loss: 1.4460 - val_acc: 0.3945\n",
            "Epoch 9/35\n",
            "49/49 [==============================] - 11s 216ms/step - loss: 1.4086 - acc: 0.4327 - val_loss: 1.4373 - val_acc: 0.4109\n",
            "Epoch 10/35\n",
            "49/49 [==============================] - 11s 220ms/step - loss: 1.4007 - acc: 0.4375 - val_loss: 1.4291 - val_acc: 0.4145\n",
            "Epoch 11/35\n",
            "49/49 [==============================] - 11s 221ms/step - loss: 1.3933 - acc: 0.4401 - val_loss: 1.4213 - val_acc: 0.4182\n",
            "Epoch 12/35\n",
            "49/49 [==============================] - 11s 222ms/step - loss: 1.3863 - acc: 0.4446 - val_loss: 1.4140 - val_acc: 0.4164\n",
            "Epoch 13/35\n",
            "49/49 [==============================] - 11s 222ms/step - loss: 1.3797 - acc: 0.4484 - val_loss: 1.4070 - val_acc: 0.4182\n",
            "Epoch 14/35\n",
            "49/49 [==============================] - 11s 225ms/step - loss: 1.3734 - acc: 0.4510 - val_loss: 1.4004 - val_acc: 0.4236\n",
            "Epoch 15/35\n",
            "49/49 [==============================] - 11s 222ms/step - loss: 1.3674 - acc: 0.4554 - val_loss: 1.3941 - val_acc: 0.4291\n",
            "Epoch 16/35\n",
            "49/49 [==============================] - 11s 224ms/step - loss: 1.3616 - acc: 0.4587 - val_loss: 1.3880 - val_acc: 0.4364\n",
            "Epoch 17/35\n",
            "49/49 [==============================] - 11s 226ms/step - loss: 1.3561 - acc: 0.4603 - val_loss: 1.3822 - val_acc: 0.4418\n",
            "Epoch 18/35\n",
            "49/49 [==============================] - 11s 222ms/step - loss: 1.3508 - acc: 0.4625 - val_loss: 1.3767 - val_acc: 0.4436\n",
            "Epoch 19/35\n",
            "49/49 [==============================] - 11s 225ms/step - loss: 1.3457 - acc: 0.4660 - val_loss: 1.3714 - val_acc: 0.4455\n",
            "Epoch 20/35\n",
            "49/49 [==============================] - 11s 223ms/step - loss: 1.3408 - acc: 0.4673 - val_loss: 1.3663 - val_acc: 0.4509\n",
            "Epoch 21/35\n",
            "49/49 [==============================] - 11s 224ms/step - loss: 1.3360 - acc: 0.4689 - val_loss: 1.3614 - val_acc: 0.4564\n",
            "Epoch 22/35\n",
            "49/49 [==============================] - 11s 229ms/step - loss: 1.3314 - acc: 0.4721 - val_loss: 1.3567 - val_acc: 0.4600\n",
            "Epoch 23/35\n",
            "49/49 [==============================] - 11s 222ms/step - loss: 1.3270 - acc: 0.4760 - val_loss: 1.3522 - val_acc: 0.4636\n",
            "Epoch 24/35\n",
            "49/49 [==============================] - 11s 227ms/step - loss: 1.3227 - acc: 0.4760 - val_loss: 1.3478 - val_acc: 0.4691\n",
            "Epoch 25/35\n",
            "49/49 [==============================] - 11s 225ms/step - loss: 1.3185 - acc: 0.4798 - val_loss: 1.3436 - val_acc: 0.4709\n",
            "Epoch 26/35\n",
            "49/49 [==============================] - 11s 225ms/step - loss: 1.3145 - acc: 0.4827 - val_loss: 1.3395 - val_acc: 0.4727\n",
            "Epoch 27/35\n",
            "49/49 [==============================] - 11s 226ms/step - loss: 1.3105 - acc: 0.4872 - val_loss: 1.3356 - val_acc: 0.4745\n",
            "Epoch 28/35\n",
            "49/49 [==============================] - 11s 225ms/step - loss: 1.3067 - acc: 0.4881 - val_loss: 1.3318 - val_acc: 0.4782\n",
            "Epoch 29/35\n",
            "49/49 [==============================] - 11s 225ms/step - loss: 1.3029 - acc: 0.4888 - val_loss: 1.3281 - val_acc: 0.4800\n",
            "Epoch 30/35\n",
            "49/49 [==============================] - 11s 222ms/step - loss: 1.2993 - acc: 0.4910 - val_loss: 1.3245 - val_acc: 0.4782\n",
            "Epoch 31/35\n",
            "49/49 [==============================] - 11s 226ms/step - loss: 1.2958 - acc: 0.4926 - val_loss: 1.3210 - val_acc: 0.4818\n",
            "Epoch 32/35\n",
            "49/49 [==============================] - 11s 225ms/step - loss: 1.2923 - acc: 0.4974 - val_loss: 1.3177 - val_acc: 0.4836\n",
            "Epoch 33/35\n",
            "49/49 [==============================] - 11s 227ms/step - loss: 1.2889 - acc: 0.4994 - val_loss: 1.3144 - val_acc: 0.4836\n",
            "Epoch 34/35\n",
            "49/49 [==============================] - 11s 226ms/step - loss: 1.2856 - acc: 0.5029 - val_loss: 1.3112 - val_acc: 0.4855\n",
            "Epoch 35/35\n",
            "49/49 [==============================] - 11s 226ms/step - loss: 1.2824 - acc: 0.5048 - val_loss: 1.3081 - val_acc: 0.4855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk_M5nFZeEOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('warmup.h5')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIgLm-WzahA8",
        "colab_type": "text"
      },
      "source": [
        "### Fine tune CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EHIchqPm_qj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "c7f3bceb-440a-459d-964a-38ee0b49c498"
      },
      "source": [
        "# prepare model and compiele\n",
        "model.layers[1].trainable = True\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
        "                     optimizer=tf.keras.optimizers.Adam(1e-5))\n",
        "\n",
        "# initialize wandb run\n",
        "wandb.init(entity='authors', project='swav-tf')\n",
        "\n",
        "# train\n",
        "history = model.fit(training_ds,\n",
        "                 validation_data=testing_ds,\n",
        "                 epochs=35,\n",
        "                 callbacks=[WandbCallback(),\n",
        "                            early_stopper])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/33umsi6u\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/33umsi6u</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "49/49 [==============================] - 34s 688ms/step - loss: 1.6727 - acc: 0.3170 - val_loss: 1.4672 - val_acc: 0.3818\n",
            "Epoch 2/35\n",
            "49/49 [==============================] - 33s 665ms/step - loss: 1.3820 - acc: 0.4279 - val_loss: 1.3446 - val_acc: 0.4691\n",
            "Epoch 3/35\n",
            "49/49 [==============================] - 33s 670ms/step - loss: 1.2861 - acc: 0.4846 - val_loss: 1.2509 - val_acc: 0.4909\n",
            "Epoch 4/35\n",
            "49/49 [==============================] - 33s 674ms/step - loss: 1.2162 - acc: 0.5212 - val_loss: 1.1584 - val_acc: 0.5364\n",
            "Epoch 5/35\n",
            "49/49 [==============================] - 33s 674ms/step - loss: 1.1146 - acc: 0.5679 - val_loss: 1.1189 - val_acc: 0.5727\n",
            "Epoch 6/35\n",
            "49/49 [==============================] - 33s 677ms/step - loss: 0.9908 - acc: 0.6179 - val_loss: 1.0413 - val_acc: 0.6345\n",
            "Epoch 7/35\n",
            "49/49 [==============================] - 32s 652ms/step - loss: 0.9558 - acc: 0.6333 - val_loss: 1.0462 - val_acc: 0.6182\n",
            "Epoch 8/35\n",
            "49/49 [==============================] - 33s 682ms/step - loss: 0.9015 - acc: 0.6574 - val_loss: 0.9623 - val_acc: 0.6309\n",
            "Epoch 9/35\n",
            "49/49 [==============================] - 32s 652ms/step - loss: 0.8148 - acc: 0.6923 - val_loss: 1.0064 - val_acc: 0.6327\n",
            "Epoch 10/35\n",
            "49/49 [==============================] - 34s 684ms/step - loss: 0.7644 - acc: 0.7144 - val_loss: 0.9135 - val_acc: 0.6673\n",
            "Epoch 11/35\n",
            "49/49 [==============================] - 32s 654ms/step - loss: 0.7150 - acc: 0.7359 - val_loss: 0.9597 - val_acc: 0.6545\n",
            "Epoch 12/35\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.6792 - acc: 0.7343Restoring model weights from the end of the best epoch.\n",
            "49/49 [==============================] - 32s 656ms/step - loss: 0.6792 - acc: 0.7343 - val_loss: 0.9153 - val_acc: 0.6818\n",
            "Epoch 00012: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vivDjXC0oF6m",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGkpf7bGoHgW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c4df5856-0ac9-4f2d-85da-d8d4c85ad3b6"
      },
      "source": [
        "loss, acc = model.evaluate(testing_ds)\n",
        "wandb.log({'Test Accuracy': round(acc*100, 2)})"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 1s 144ms/step - loss: 0.9135 - acc: 0.6673\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "966mDKFhqsrk",
        "colab_type": "text"
      },
      "source": [
        "# Training with Augmentation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPlQ3JKtq6j-",
        "colab_type": "text"
      },
      "source": [
        "### Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hACfOEyQnk4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configs\n",
        "CROP_SIZE = 224\n",
        "MIN_SCALE = 0.5\n",
        "MAX_SCALE = 1.\n",
        "\n",
        "# Experimental options\n",
        "options = tf.data.Options()\n",
        "options.experimental_optimization.noop_elimination = True\n",
        "options.experimental_optimization.map_vectorization.enabled = True\n",
        "options.experimental_optimization.apply_default_optimizations = True\n",
        "options.experimental_deterministic = False\n",
        "options.experimental_threading.max_intra_op_parallelism = 1"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU2OZh1oTFaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def scale_image(image, label):\n",
        "\timage = tf.image.convert_image_dtype(image, tf.float32)\n",
        "\treturn (image, label)\n",
        "\n",
        "@tf.function\n",
        "def random_apply(func, x, p):\n",
        "\treturn tf.cond(\n",
        "\t\ttf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
        "\t\t\t\ttf.cast(p, tf.float32)),\n",
        "\t\tlambda: func(x),\n",
        "\t\tlambda: x)\n",
        " \n",
        "@tf.function\n",
        "def random_resize_crop(image, label):\n",
        "  # Conditional resizing\n",
        "  image = tf.image.resize(image, (260, 260))\n",
        "  # Get the crop size for given min and max scale\n",
        "  size = tf.random.uniform(shape=(1,), minval=MIN_SCALE*260,\n",
        "\t\t          maxval=MAX_SCALE*260, dtype=tf.float32)\n",
        "  size = tf.cast(size, tf.int32)[0]\n",
        "  # Get the crop from the image\n",
        "  crop = tf.image.random_crop(image, (size,size,3))\n",
        "  crop_resize = tf.image.resize(crop, (CROP_SIZE, CROP_SIZE))\n",
        "  \n",
        "  return crop_resize, label\n",
        "\n",
        "@tf.function\n",
        "def tie_together(image, label):\n",
        "  # Scale the pixel values\n",
        "  image, label = scale_image(image , label)\n",
        "  # random horizontal flip\n",
        "  image = random_apply(tf.image.random_flip_left_right, image, p=0.5)\n",
        "  # Random resized crops\n",
        "  image, label = random_resize_crop(image, label)\n",
        "  \n",
        "  return image, label"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLzlomx_d2iO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = (\n",
        "\ttrain_ds\n",
        "\t.shuffle(1024)\n",
        "\t.map(tie_together, num_parallel_calls=AUTO)\n",
        "\t.batch(BATCH_SIZE)\n",
        "\t.prefetch(AUTO)\n",
        ")\n",
        "\n",
        "trainloader = trainloader.with_options(options)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PBzTIQAqtsLu"
      },
      "source": [
        "### Warmup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pat13QzdtsL3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "43a341f9-50b7-499b-bfa4-8bdee93b538d"
      },
      "source": [
        "# get model and compile\n",
        "model = get_training_model()\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
        "                     optimizer='adam')\n",
        "\n",
        "# initialize wandb run\n",
        "wandb.init(entity='authors', project='swav-tf')\n",
        "\n",
        "# train\n",
        "history = model.fit(trainloader,\n",
        "                 validation_data=testing_ds,\n",
        "                 epochs=35,\n",
        "                 callbacks=[WandbCallback(),\n",
        "                            early_stopper])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/nvbd9gx6\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/nvbd9gx6</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "49/49 [==============================] - 11s 232ms/step - loss: 1.5935 - acc: 0.2657 - val_loss: 1.5471 - val_acc: 0.3036\n",
            "Epoch 2/35\n",
            "49/49 [==============================] - 11s 217ms/step - loss: 1.5420 - acc: 0.3426 - val_loss: 1.5299 - val_acc: 0.3436\n",
            "Epoch 3/35\n",
            "49/49 [==============================] - 11s 219ms/step - loss: 1.5271 - acc: 0.3561 - val_loss: 1.5070 - val_acc: 0.3436\n",
            "Epoch 4/35\n",
            "49/49 [==============================] - 11s 219ms/step - loss: 1.5095 - acc: 0.3561 - val_loss: 1.4881 - val_acc: 0.3636\n",
            "Epoch 5/35\n",
            "49/49 [==============================] - 11s 222ms/step - loss: 1.5013 - acc: 0.3644 - val_loss: 1.4764 - val_acc: 0.3800\n",
            "Epoch 6/35\n",
            "49/49 [==============================] - 11s 221ms/step - loss: 1.4851 - acc: 0.3718 - val_loss: 1.4602 - val_acc: 0.3964\n",
            "Epoch 7/35\n",
            "49/49 [==============================] - 10s 210ms/step - loss: 1.4782 - acc: 0.3785 - val_loss: 1.5021 - val_acc: 0.3582\n",
            "Epoch 8/35\n",
            "49/49 [==============================] - ETA: 0s - loss: 1.4706 - acc: 0.3795Restoring model weights from the end of the best epoch.\n",
            "49/49 [==============================] - 11s 215ms/step - loss: 1.4706 - acc: 0.3795 - val_loss: 1.4648 - val_acc: 0.3927\n",
            "Epoch 00008: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD-oqM7wslOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('warmup_augmentation.h5')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q0IBzaXysj60"
      },
      "source": [
        "### Fine tune CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3BoSzbemsj7F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "outputId": "4b686284-ca7e-45ff-c8da-af5fafb0db26"
      },
      "source": [
        "# prepare model and compiele\n",
        "model.layers[1].trainable = True\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
        "                     optimizer=tf.keras.optimizers.Adam(1e-5))\n",
        "\n",
        "# initialize wandb run\n",
        "wandb.init(entity='authors', project='swav-tf')\n",
        "\n",
        "# train\n",
        "history = model.fit(trainloader,\n",
        "                 validation_data=testing_ds,\n",
        "                 epochs=35,\n",
        "                 callbacks=[WandbCallback(),\n",
        "                            early_stopper])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/1nhh7egp\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/1nhh7egp</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "49/49 [==============================] - 33s 671ms/step - loss: 1.6167 - acc: 0.2792 - val_loss: 1.5346 - val_acc: 0.3418\n",
            "Epoch 2/35\n",
            "49/49 [==============================] - 31s 632ms/step - loss: 1.5041 - acc: 0.3535 - val_loss: 1.7565 - val_acc: 0.1782\n",
            "Epoch 3/35\n",
            "49/49 [==============================] - 33s 664ms/step - loss: 1.4996 - acc: 0.3683 - val_loss: 1.3907 - val_acc: 0.4509\n",
            "Epoch 4/35\n",
            "49/49 [==============================] - 33s 671ms/step - loss: 1.4181 - acc: 0.4093 - val_loss: 1.3449 - val_acc: 0.4364\n",
            "Epoch 5/35\n",
            "49/49 [==============================] - 33s 672ms/step - loss: 1.3706 - acc: 0.4311 - val_loss: 1.3143 - val_acc: 0.4927\n",
            "Epoch 6/35\n",
            "49/49 [==============================] - 32s 646ms/step - loss: 1.3665 - acc: 0.4349 - val_loss: 1.3287 - val_acc: 0.4636\n",
            "Epoch 7/35\n",
            "49/49 [==============================] - 33s 678ms/step - loss: 1.2956 - acc: 0.4715 - val_loss: 1.2758 - val_acc: 0.4691\n",
            "Epoch 8/35\n",
            "49/49 [==============================] - 33s 674ms/step - loss: 1.2930 - acc: 0.4683 - val_loss: 1.2572 - val_acc: 0.5036\n",
            "Epoch 9/35\n",
            "49/49 [==============================] - 33s 677ms/step - loss: 1.2202 - acc: 0.5138 - val_loss: 1.1707 - val_acc: 0.5491\n",
            "Epoch 10/35\n",
            "49/49 [==============================] - 33s 680ms/step - loss: 1.1907 - acc: 0.5157 - val_loss: 1.1707 - val_acc: 0.4909\n",
            "Epoch 11/35\n",
            "49/49 [==============================] - 32s 652ms/step - loss: 1.1072 - acc: 0.5663 - val_loss: 1.2217 - val_acc: 0.5400\n",
            "Epoch 12/35\n",
            "49/49 [==============================] - 33s 678ms/step - loss: 1.0897 - acc: 0.5744 - val_loss: 0.8830 - val_acc: 0.6673\n",
            "Epoch 13/35\n",
            "49/49 [==============================] - 32s 653ms/step - loss: 0.9965 - acc: 0.6147 - val_loss: 0.8842 - val_acc: 0.6636\n",
            "Epoch 14/35\n",
            "49/49 [==============================] - 33s 679ms/step - loss: 0.9851 - acc: 0.6263 - val_loss: 0.8476 - val_acc: 0.7273\n",
            "Epoch 15/35\n",
            "49/49 [==============================] - 33s 683ms/step - loss: 0.8858 - acc: 0.6567 - val_loss: 0.7615 - val_acc: 0.7509\n",
            "Epoch 16/35\n",
            "49/49 [==============================] - 32s 653ms/step - loss: 0.8617 - acc: 0.6696 - val_loss: 0.8661 - val_acc: 0.6909\n",
            "Epoch 17/35\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.8522 - acc: 0.6753Restoring model weights from the end of the best epoch.\n",
            "49/49 [==============================] - 32s 657ms/step - loss: 0.8522 - acc: 0.6753 - val_loss: 0.8929 - val_acc: 0.6909\n",
            "Epoch 00017: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ghvNZKDZuvmC"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "royxn_DLuvmF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f4ff7815-6d88-4977-8f31-115d92e59e43"
      },
      "source": [
        "loss, acc = model.evaluate(testing_ds)\n",
        "wandb.log({'Test Accuracy': round(acc*100, 2)})"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 1s 146ms/step - loss: 0.7615 - acc: 0.7509\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}