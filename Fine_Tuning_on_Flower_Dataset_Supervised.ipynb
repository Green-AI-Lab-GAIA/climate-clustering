{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine_Tuning_on_Flower_Dataset_Supervised.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayulockin/SwAV-TF/blob/master/Fine_Tuning_on_Flower_Dataset_Supervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhtA_QHMgNMw",
        "colab_type": "text"
      },
      "source": [
        "# Imports and Setups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1c99jQL0KMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "\n",
        "tf.random.set_seed(666)\n",
        "np.random.seed(666)\n",
        "\n",
        "tfds.disable_progress_bar()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajrzwUMZgRRi",
        "colab_type": "text"
      },
      "source": [
        "### W&B - Experiment Tracking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTsiFHLcgVpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install wandb "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V53zG0-vgYdO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f3afa664-7aea-42d4-c830-6d5a6b5f98ee"
      },
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "wandb.login()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://app.wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnhWEo8_12FK",
        "colab_type": "text"
      },
      "source": [
        "## Dataset gathering and preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAOhOFMs110h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "e4c2cfb2-ef2c-4feb-972e-08dfb3ad857b"
      },
      "source": [
        "# Gather Flowers dataset\n",
        "train_ds, extra_train_ds, validation_ds = tfds.load(\n",
        "    \"tf_flowers\",\n",
        "    split=[\"train[:10%]\", \"train[10%:85%]\", \"train[85%:]\"],\n",
        "    as_supervised=True\n",
        ")\n",
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "@tf.function\n",
        "def scale_resize_image(image, label):\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = tf.image.resize(image, (224, 224)) # Resizing to highest resolution used while training swav\n",
        "    return (image, label)\n",
        "\n",
        "training_ds = (\n",
        "    train_ds\n",
        "    .map(scale_resize_image, num_parallel_calls=AUTO)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "testing_ds = (\n",
        "    validation_ds\n",
        "    .map(scale_resize_image, num_parallel_calls=AUTO)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset tf_flowers is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead set\n",
            "data_dir=gs://tfds-data/datasets.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset tf_flowers/3.0.0 (download: 218.21 MiB, generated: Unknown size, total: 218.21 MiB) to /root/tensorflow_datasets/tf_flowers/3.0.0...\u001b[0m\n",
            "\u001b[1mDataset tf_flowers downloaded and prepared to /root/tensorflow_datasets/tf_flowers/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqOBLHJa5Ztp",
        "colab_type": "text"
      },
      "source": [
        "## ResNet50 base and a custom classification head"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znqofzfr46-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_training_model(trainable=False):\n",
        "    inputs = layers.Input(shape=(224, 224, 3))\n",
        "    EXTRACTOR = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False,\n",
        "        input_shape=(224, 224, 3))\n",
        "    EXTRACTOR.trainable = trainable\n",
        "    x = EXTRACTOR(inputs, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(5, activation=\"softmax\")(x)\n",
        "    classifier = models.Model(inputs=inputs, outputs=x)\n",
        "    \n",
        "    return classifier"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtt4jmzzxe8Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "af8e19c3-a152-4db4-ccf9-788b90d54bff"
      },
      "source": [
        "model = get_training_model()\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 10245     \n",
            "=================================================================\n",
            "Total params: 23,597,957\n",
            "Trainable params: 10,245\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0o5LHV0pCPu",
        "colab_type": "text"
      },
      "source": [
        "## Callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vECu62eyCdut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Early Stopping to prevent overfitting\n",
        "early_stopper = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2, verbose=2, restore_best_weights=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp1fJIEYpFIC",
        "colab_type": "text"
      },
      "source": [
        "## Without Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEY1h0L2XjBJ",
        "colab_type": "text"
      },
      "source": [
        "### Warm Up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RArUvFToDJKn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "c639a782-60b6-425c-c659-70b88b71e6db"
      },
      "source": [
        "# get model and compile\n",
        "tf.keras.backend.clear_session()\n",
        "model = get_training_model()\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
        "                     optimizer='adam')\n",
        "\n",
        "# initialize wandb run\n",
        "wandb.init(entity='authors', project='swav-tf')\n",
        "\n",
        "# train\n",
        "history = model.fit(training_ds,\n",
        "                 validation_data=testing_ds,\n",
        "                 epochs=35,\n",
        "                 callbacks=[WandbCallback(),\n",
        "                            early_stopper])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/35dokky0\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/35dokky0</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "6/6 [==============================] - 3s 513ms/step - loss: 1.8391 - acc: 0.2044 - val_loss: 1.6250 - val_acc: 0.2055\n",
            "Epoch 2/35\n",
            "6/6 [==============================] - 2s 320ms/step - loss: 1.6024 - acc: 0.2888 - val_loss: 1.7046 - val_acc: 0.2145\n",
            "Epoch 3/35\n",
            "6/6 [==============================] - ETA: 0s - loss: 1.6264 - acc: 0.3079Restoring model weights from the end of the best epoch.\n",
            "6/6 [==============================] - 2s 359ms/step - loss: 1.6264 - acc: 0.3079 - val_loss: 1.6490 - val_acc: 0.2436\n",
            "Epoch 00003: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk_M5nFZeEOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('warmup.h5')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIgLm-WzahA8",
        "colab_type": "text"
      },
      "source": [
        "### Fine tune CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EHIchqPm_qj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "e025ce51-906e-4eb0-bf39-72ab218587d7"
      },
      "source": [
        "# prepare model and compile\n",
        "model.layers[1].trainable = True\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
        "                     optimizer=tf.keras.optimizers.Adam(1e-5))\n",
        "\n",
        "# initialize wandb run\n",
        "wandb.init(entity='authors', project='swav-tf')\n",
        "\n",
        "# train\n",
        "history = model.fit(training_ds,\n",
        "                 validation_data=testing_ds,\n",
        "                 epochs=35,\n",
        "                 callbacks=[WandbCallback(),\n",
        "                            early_stopper])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/2s15oid1\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/2s15oid1</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "6/6 [==============================] - 6s 924ms/step - loss: 1.5775 - acc: 0.3025 - val_loss: 1.5856 - val_acc: 0.2527\n",
            "Epoch 2/35\n",
            "6/6 [==============================] - 3s 507ms/step - loss: 1.5114 - acc: 0.3542 - val_loss: 1.6024 - val_acc: 0.2491\n",
            "Epoch 3/35\n",
            "6/6 [==============================] - ETA: 0s - loss: 1.4678 - acc: 0.3651Restoring model weights from the end of the best epoch.\n",
            "6/6 [==============================] - 3s 519ms/step - loss: 1.4678 - acc: 0.3651 - val_loss: 1.6279 - val_acc: 0.2527\n",
            "Epoch 00003: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A1MEseWih3a",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmXHuzBGijmH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5ac1eda6-6942-4fbe-84f4-209c8b5eae3b"
      },
      "source": [
        "loss, acc = model.evaluate(testing_ds)\n",
        "wandb.log({'Test Accuracy': round(acc*100, 2)})"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 1s 107ms/step - loss: 1.5856 - acc: 0.2527\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "966mDKFhqsrk",
        "colab_type": "text"
      },
      "source": [
        "# Training with Augmentation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPlQ3JKtq6j-",
        "colab_type": "text"
      },
      "source": [
        "### Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hACfOEyQnk4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configs\n",
        "CROP_SIZE = 224\n",
        "MIN_SCALE = 0.5\n",
        "MAX_SCALE = 1.\n",
        "\n",
        "# Experimental options\n",
        "options = tf.data.Options()\n",
        "options.experimental_optimization.noop_elimination = True\n",
        "options.experimental_optimization.map_vectorization.enabled = True\n",
        "options.experimental_optimization.apply_default_optimizations = True\n",
        "options.experimental_deterministic = False\n",
        "options.experimental_threading.max_intra_op_parallelism = 1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU2OZh1oTFaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def scale_image(image, label):\n",
        "\timage = tf.image.convert_image_dtype(image, tf.float32)\n",
        "\treturn (image, label)\n",
        "\n",
        "@tf.function\n",
        "def random_apply(func, x, p):\n",
        "\treturn tf.cond(\n",
        "\t\ttf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
        "\t\t\t\ttf.cast(p, tf.float32)),\n",
        "\t\tlambda: func(x),\n",
        "\t\tlambda: x)\n",
        " \n",
        "@tf.function\n",
        "def random_resize_crop(image, label):\n",
        "  # Conditional resizing\n",
        "  image = tf.image.resize(image, (260, 260))\n",
        "  # Get the crop size for given min and max scale\n",
        "  size = tf.random.uniform(shape=(1,), minval=MIN_SCALE*260,\n",
        "\t\t          maxval=MAX_SCALE*260, dtype=tf.float32)\n",
        "  size = tf.cast(size, tf.int32)[0]\n",
        "  # Get the crop from the image\n",
        "  crop = tf.image.random_crop(image, (size,size,3))\n",
        "  crop_resize = tf.image.resize(crop, (CROP_SIZE, CROP_SIZE))\n",
        "  \n",
        "  return crop_resize, label\n",
        "\n",
        "@tf.function\n",
        "def tie_together(image, label):\n",
        "  # Scale the pixel values\n",
        "  image, label = scale_image(image , label)\n",
        "  # random horizontal flip\n",
        "  image = random_apply(tf.image.random_flip_left_right, image, p=0.5)\n",
        "  # Random resized crops\n",
        "  image, label = random_resize_crop(image, label)\n",
        "  \n",
        "  return image, label"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLzlomx_d2iO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = (\n",
        "\ttrain_ds\n",
        "\t.shuffle(1024)\n",
        "\t.map(tie_together, num_parallel_calls=AUTO)\n",
        "\t.batch(BATCH_SIZE)\n",
        "\t.prefetch(AUTO)\n",
        ")\n",
        "\n",
        "trainloader = trainloader.with_options(options)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PBzTIQAqtsLu"
      },
      "source": [
        "### Warmup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pat13QzdtsL3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "outputId": "7dc44acf-77f3-47ed-e35c-400a95ccce5a"
      },
      "source": [
        "# get model and compile\n",
        "tf.keras.backend.clear_session()\n",
        "model = get_training_model()\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
        "                     optimizer='adam')\n",
        "\n",
        "# initialize wandb run\n",
        "wandb.init(entity='authors', project='swav-tf')\n",
        "\n",
        "# train\n",
        "history = model.fit(trainloader,\n",
        "                 validation_data=testing_ds,\n",
        "                 epochs=35,\n",
        "                 callbacks=[WandbCallback(),\n",
        "                            early_stopper])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/35sb2ql5\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/35sb2ql5</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "6/6 [==============================] - 3s 509ms/step - loss: 1.8788 - acc: 0.2916 - val_loss: 1.6496 - val_acc: 0.2055\n",
            "Epoch 2/35\n",
            "6/6 [==============================] - 2s 400ms/step - loss: 1.6126 - acc: 0.2343 - val_loss: 1.6411 - val_acc: 0.2291\n",
            "Epoch 3/35\n",
            "6/6 [==============================] - 3s 452ms/step - loss: 1.6228 - acc: 0.2561 - val_loss: 1.6226 - val_acc: 0.2145\n",
            "Epoch 4/35\n",
            "6/6 [==============================] - 3s 476ms/step - loss: 1.5738 - acc: 0.2970 - val_loss: 1.6112 - val_acc: 0.2200\n",
            "Epoch 5/35\n",
            "6/6 [==============================] - 3s 450ms/step - loss: 1.5685 - acc: 0.3106 - val_loss: 1.5797 - val_acc: 0.2764\n",
            "Epoch 6/35\n",
            "6/6 [==============================] - 3s 463ms/step - loss: 1.5490 - acc: 0.3433 - val_loss: 1.5661 - val_acc: 0.2745\n",
            "Epoch 7/35\n",
            "6/6 [==============================] - 3s 459ms/step - loss: 1.5447 - acc: 0.3134 - val_loss: 1.5596 - val_acc: 0.2582\n",
            "Epoch 8/35\n",
            "6/6 [==============================] - 2s 410ms/step - loss: 1.5371 - acc: 0.3324 - val_loss: 1.5488 - val_acc: 0.2873\n",
            "Epoch 9/35\n",
            "6/6 [==============================] - 2s 369ms/step - loss: 1.5249 - acc: 0.3188 - val_loss: 1.5543 - val_acc: 0.2909\n",
            "Epoch 10/35\n",
            "6/6 [==============================] - 2s 400ms/step - loss: 1.5322 - acc: 0.3433 - val_loss: 1.5324 - val_acc: 0.3145\n",
            "Epoch 11/35\n",
            "6/6 [==============================] - 3s 460ms/step - loss: 1.5231 - acc: 0.3569 - val_loss: 1.5320 - val_acc: 0.2982\n",
            "Epoch 12/35\n",
            "6/6 [==============================] - 3s 462ms/step - loss: 1.5125 - acc: 0.3406 - val_loss: 1.5309 - val_acc: 0.2945\n",
            "Epoch 13/35\n",
            "6/6 [==============================] - 3s 447ms/step - loss: 1.5105 - acc: 0.3787 - val_loss: 1.5176 - val_acc: 0.3582\n",
            "Epoch 14/35\n",
            "6/6 [==============================] - 2s 372ms/step - loss: 1.5085 - acc: 0.3733 - val_loss: 1.5305 - val_acc: 0.2964\n",
            "Epoch 15/35\n",
            "6/6 [==============================] - ETA: 0s - loss: 1.5103 - acc: 0.3406Restoring model weights from the end of the best epoch.\n",
            "6/6 [==============================] - 2s 334ms/step - loss: 1.5103 - acc: 0.3406 - val_loss: 1.5209 - val_acc: 0.3109\n",
            "Epoch 00015: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD-oqM7wslOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('warmup_augmentation.h5')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q0IBzaXysj60"
      },
      "source": [
        "### Fine tune CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3BoSzbemsj7F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "f3399094-27d6-4df7-960f-5ae0cb24d593"
      },
      "source": [
        "# prepare model and compile\n",
        "model.layers[1].trainable = True\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"],\n",
        "                     optimizer=tf.keras.optimizers.Adam(1e-5))\n",
        "\n",
        "# initialize wandb run\n",
        "wandb.init(entity='authors', project='swav-tf')\n",
        "\n",
        "# train\n",
        "history = model.fit(trainloader,\n",
        "                 validation_data=testing_ds,\n",
        "                 epochs=35,\n",
        "                 callbacks=[WandbCallback(),\n",
        "                            early_stopper])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/swav-tf\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/authors/swav-tf/runs/ailwhscb\" target=\"_blank\">https://app.wandb.ai/authors/swav-tf/runs/ailwhscb</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "6/6 [==============================] - 5s 835ms/step - loss: 1.5755 - acc: 0.3488 - val_loss: 1.5523 - val_acc: 0.2655\n",
            "Epoch 2/35\n",
            "6/6 [==============================] - 4s 716ms/step - loss: 1.5667 - acc: 0.3025 - val_loss: 1.5421 - val_acc: 0.3273\n",
            "Epoch 3/35\n",
            "6/6 [==============================] - 4s 714ms/step - loss: 1.5191 - acc: 0.3433 - val_loss: 1.5387 - val_acc: 0.2927\n",
            "Epoch 4/35\n",
            "6/6 [==============================] - 4s 735ms/step - loss: 1.4997 - acc: 0.3460 - val_loss: 1.5335 - val_acc: 0.3309\n",
            "Epoch 5/35\n",
            "6/6 [==============================] - 3s 494ms/step - loss: 1.5293 - acc: 0.3515 - val_loss: 1.5361 - val_acc: 0.3400\n",
            "Epoch 6/35\n",
            "6/6 [==============================] - 4s 697ms/step - loss: 1.5210 - acc: 0.3515 - val_loss: 1.5091 - val_acc: 0.3145\n",
            "Epoch 7/35\n",
            "6/6 [==============================] - 3s 527ms/step - loss: 1.4800 - acc: 0.3978 - val_loss: 1.5227 - val_acc: 0.3036\n",
            "Epoch 8/35\n",
            "6/6 [==============================] - ETA: 0s - loss: 1.4849 - acc: 0.3569Restoring model weights from the end of the best epoch.\n",
            "6/6 [==============================] - 3s 517ms/step - loss: 1.4849 - acc: 0.3569 - val_loss: 1.5192 - val_acc: 0.3345\n",
            "Epoch 00008: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "prZcXHyskW4f"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mztmMjICkW4r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "81a96173-ab0f-491b-fc58-5e2f54ca6f9f"
      },
      "source": [
        "loss, acc = model.evaluate(testing_ds)\n",
        "wandb.log({'Test Accuracy': round(acc*100, 2)})"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 1s 108ms/step - loss: 1.5091 - acc: 0.3145\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}