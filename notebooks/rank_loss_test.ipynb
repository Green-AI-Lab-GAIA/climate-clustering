{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "334149e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "#add ../ to path\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '../'))\n",
    "\n",
    "from src.data_manager import (\n",
    "    init_data,\n",
    "    make_transforms\n",
    ")\n",
    "from src.utils import init_distributed\n",
    "import src.msn_train as msn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "78fe6dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs/temp.yaml', 'r') as y_file:\n",
    "    args = yaml.load(y_file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "191842d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- META\n",
    "world_size, rank = 1,1\n",
    "model_name = args['meta']['model_name']\n",
    "two_layer = False if 'two_layer' not in args['meta'] else args['meta']['two_layer']\n",
    "bottleneck = 1 if 'bottleneck' not in args['meta'] else args['meta']['bottleneck']\n",
    "output_dim = args['meta']['output_dim']\n",
    "hidden_dim = args['meta']['hidden_dim']\n",
    "load_model = args['meta']['load_checkpoint']\n",
    "r_file = args['meta']['read_checkpoint']\n",
    "# copy_data = args['meta']['copy_data']\n",
    "use_pred_head = args['meta']['use_pred_head']\n",
    "use_bn = args['meta']['use_bn']\n",
    "drop_path_rate = args['meta']['drop_path_rate']\n",
    "if not torch.cuda.is_available():\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    device = torch.device('cuda:0')\n",
    "    torch.cuda.set_device(device)\n",
    "\n",
    "# -- CRITERTION\n",
    "memax_weight = 1 if 'memax_weight' not in args['criterion'] else args['criterion']['memax_weight']\n",
    "ent_weight = 1 if 'ent_weight' not in args['criterion'] else args['criterion']['ent_weight']\n",
    "freeze_proto = False if 'freeze_proto' not in args['criterion'] else args['criterion']['freeze_proto']\n",
    "use_ent = False if 'use_ent' not in args['criterion'] else args['criterion']['use_ent']\n",
    "reg = args['criterion']['me_max']\n",
    "use_sinkhorn = args['criterion']['use_sinkhorn']\n",
    "num_proto = args['criterion']['num_proto']\n",
    "# --\n",
    "# batch_size = args['criterion']['batch_size']\n",
    "batch_size = 64\n",
    "temperature = args['criterion']['temperature']\n",
    "_start_T = args['criterion']['start_sharpen']\n",
    "_final_T = args['criterion']['final_sharpen']\n",
    "\n",
    "# -- DATA\n",
    "label_smoothing = args['data']['label_smoothing']\n",
    "pin_mem = False if 'pin_mem' not in args['data'] else args['data']['pin_mem']\n",
    "num_workers = 1 if 'num_workers' not in args['data'] else args['data']['num_workers']\n",
    "norm_means = args['data']['norm_means']\n",
    "norm_stds = args['data']['norm_stds']\n",
    "# root_path = args['data']['root_path']\n",
    "# image_folder = args['data']['image_folder']\n",
    "patch_drop = args['data']['patch_drop']\n",
    "rand_size = args['data']['rand_size']\n",
    "rand_views = args['data']['rand_views']\n",
    "focal_views = args['data']['focal_views']\n",
    "focal_size = args['data']['focal_size']\n",
    "surf_vars = args['data']['surf_vars']\n",
    "static_vars = args['data']['static_vars']\n",
    "lat_lim = args['data']['lat_limit']\n",
    "lon_lim = args['data']['lon_limit']\n",
    "split_val = args['data']['split_val']\n",
    "\n",
    "# --\n",
    "\n",
    "# -- OPTIMIZATION\n",
    "clip_grad = args['optimization']['clip_grad']\n",
    "wd = float(args['optimization']['weight_decay'])\n",
    "final_wd = float(args['optimization']['final_weight_decay'])\n",
    "# num_epochs = args['optimization']['epochs']\n",
    "num_epochs = 100\n",
    "warmup = args['optimization']['warmup']\n",
    "start_lr = args['optimization']['start_lr']\n",
    "lr = args['optimization']['lr']\n",
    "final_lr = args['optimization']['final_lr']\n",
    "\n",
    "# -- LOGGING\n",
    "folder = args['logging']['folder']\n",
    "tag = args['logging']['write_tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c54b02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_manager import BrazilWeatherDataset\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "            norm_means,\n",
    "            norm_stds)\n",
    "\n",
    "\n",
    "dataset = BrazilWeatherDataset( transform=normalize,\n",
    "                                surf_vars=surf_vars,\n",
    "                                static_vars=static_vars,\n",
    "                                lat_lim=lat_lim, lon_lim=lon_lim,\n",
    "                                adj_prep_balance=False,\n",
    "                                split_val=True,\n",
    "                                return_time_period=True)\n",
    "\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=pin_mem,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6213f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.climate.gov/news-features/understanding-climate/climate-variability-oceanic-nino-index\n",
    "oni_index = pd.read_excel('data/oni_index.xlsx')\n",
    "oni_index.set_index('Year', inplace=True)\n",
    "oni_index.columns.name='Month'\n",
    "original_col = list( oni_index.columns)\n",
    "new_cols = [i for i in range(2,13)]+[1] #ultimo mes da média móvel\n",
    "oni_index.columns = new_cols\n",
    "oni_index= oni_index.unstack().to_frame('ONI')\n",
    "\n",
    "oni_index['date_period'] = pd.to_datetime(oni_index.index.map(lambda x: f\"{x[1]}-{x[0]}-01\")).to_period('M')\n",
    "oni_index['date_period'] = oni_index['date_period'].apply(lambda x: x.ordinal)\n",
    "\n",
    "oni_index.set_index('date_period', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7af7f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:VisionTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(2, 384, kernel_size=(16, 16), stride=(16, 16))\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (blocks): ModuleList(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1-11): 11 x Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "  (fc): Sequential(\n",
      "    (fc1): Linear(in_features=384, out_features=2048, bias=True)\n",
      "    (gelu1): GELU(approximate='none')\n",
      "    (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "    (gelu2): GELU(approximate='none')\n",
      "    (fc3): Linear(in_features=2048, out_features=128, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_name = 'deit_small_temperature'\n",
    "device = torch.cuda.current_device() if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "encoder = msn.init_model(device=device,model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6aba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LabelDifference(nn.Module):\n",
    "    def __init__(self, distance_type='l1'):\n",
    "        super(LabelDifference, self).__init__()\n",
    "        self.distance_type = distance_type\n",
    "\n",
    "    def forward(self, labels):\n",
    "        # labels: [bs, label_dim]\n",
    "        # output: [bs, bs]\n",
    "        if self.distance_type == 'l1':\n",
    "            return torch.abs(labels[:, None, :] - labels[None, :, :]).sum(dim=-1)\n",
    "        else:\n",
    "            raise ValueError(self.distance_type)\n",
    "\n",
    "\n",
    "class FeatureSimilarity(nn.Module):\n",
    "    def __init__(self, similarity_type='l2'):\n",
    "        super(FeatureSimilarity, self).__init__()\n",
    "        self.similarity_type = similarity_type\n",
    "\n",
    "    def forward(self, features):\n",
    "        # labels: [bs, feat_dim]\n",
    "        # output: [bs, bs]\n",
    "        if self.similarity_type == 'l2':\n",
    "            return - (features[:, None, :] - features[None, :, :]).norm(2, dim=-1)\n",
    "        else:\n",
    "            raise ValueError(self.similarity_type)\n",
    "\n",
    "\n",
    "class RnCLoss(nn.Module):\n",
    "    def __init__(self, temperature=2, label_diff='l1', feature_sim='l2'):\n",
    "        super(RnCLoss, self).__init__()\n",
    "        self.t = temperature\n",
    "        self.label_diff_fn = LabelDifference(label_diff)\n",
    "        self.feature_sim_fn = FeatureSimilarity(feature_sim)\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        # features: [bs, 2, feat_dim]\n",
    "        # labels: [bs, label_dim]\n",
    "\n",
    "        # features = torch.cat([features[:, 0], features[:, 1]], dim=0)  # [2bs, feat_dim]\n",
    "        # labels = labels.repeat(2, 1)  # [2bs, label_dim]\n",
    "\n",
    "        label_diffs = self.label_diff_fn(labels)\n",
    "        logits = self.feature_sim_fn(features).div(self.t)\n",
    "        logits_max, _ = torch.max(logits, dim=1, keepdim=True)\n",
    "        logits -= logits_max.detach()\n",
    "        exp_logits = logits.exp()\n",
    "\n",
    "        n = logits.shape[0]  # n = 2bs\n",
    "\n",
    "        # remove diagonal\n",
    "        logits = logits.masked_select((1 - torch.eye(n).to(logits.device)).bool()).view(n, n - 1)\n",
    "        exp_logits = exp_logits.masked_select((1 - torch.eye(n).to(logits.device)).bool()).view(n, n - 1)\n",
    "        label_diffs = label_diffs.masked_select((1 - torch.eye(n).to(logits.device)).bool()).view(n, n - 1)\n",
    "\n",
    "        loss = 0.\n",
    "        for k in range(n - 1):\n",
    "            pos_logits = logits[:, k]  # 2bs\n",
    "            pos_label_diffs = label_diffs[:, k]  # 2bs\n",
    "            neg_mask = (label_diffs >= pos_label_diffs.view(-1, 1)).float()  # [2bs, 2bs - 1]\n",
    "            pos_log_probs = pos_logits - torch.log((neg_mask * exp_logits).sum(dim=-1))  # 2bs\n",
    "            loss += - (pos_log_probs / (n * (n - 1))).sum()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ab44fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = RnCLoss(temperature=2, label_diff='l1', feature_sim='l2')\n",
    "optimizer = torch.optim.AdamW(encoder.parameters(), lr=lr, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632b963a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100] Iter [1397/1398] Loss: 0.9593\n",
      "Epoch [10/100] Iter [1397/1398] Loss: 0.9825\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m     labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(oni_index\u001b[38;5;241m.\u001b[39mloc[utime\u001b[38;5;241m.\u001b[39mnumpy()][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mONI\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(anchor_views, labels)\n\u001b[0;32m---> 14\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Documentos/Projetos/climate-clustering/.venv/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/Projetos/climate-clustering/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/Projetos/climate-clustering/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(0, num_epochs):\n",
    "\n",
    "    for itr, (udata, utime) in enumerate(data_loader):\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        _, z = encoder(udata.to(device), return_before_head=True, patch_drop=patch_drop)\n",
    "        anchor_views =  z.float()\n",
    "        labels = torch.tensor(oni_index.loc[utime.numpy()]['ONI'].values).unsqueeze(-1).to(device)\n",
    "\n",
    "        loss = criterion(anchor_views, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch [ {epoch}/{num_epochs}] Iter [{itr}/{len(data_loader)}] Loss: {loss.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate-clustering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
